---
title: "Exercises"
output: html_document
---

#### __Conceptual__

##### __1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.__

__(a) The sample size n is extremely large, and the number of predictors p is small.__

- **Better** : A large sample size means a flexible model will be able to better fit the data

__(b) The number of predictors p is extremely large, and the number of observations n is small.__

- **Worse** : Fitting a more flexible model with greater number of predictors and small number of observations would lead to a phenomenon called overfitting. Flexible methods generally do better when large datasets are available.

__(c) The relationship between the predictors and response is highly non-linear.__

- **Better** : Flexible methods perform better on non-linear datasets as they have more degrees of freedom to approximate a non-linear

__(d) The variance of the error terms, i.e. σ^2 = Var(ε), is extremely high.__

- **Worse** : A flexible model would likely overfit. The model would follow the errors in the data. This hints that f is linear and so a simpler model would better be able to estimate $f$.


##### __2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p__

__(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.__

- **Regression** : The response in this case is quantitative
- **Inference** : We want to understand which factors affect CEO salary
- n = 500, p = profit, number of employees, industry, and CEO salary

__(b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.__

- **Classification** : Responses are "success" and "failure"
- **Prediction** : We wish to predict whether the new product will be a success or failure
- n = 20, p = Binary value(success & failure), price, marketing budget, competition price, and 10 other variables

__(c) We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.__

- **Regression** : % change in the USD/Euro is a quantitative value
- **Prediction** : We want to predict the % change
- n = 52(weeks), p = % change in the USD/Euro, % change in the US market, % change in the British market, % change in German market

##### __3. We now revisit thee bias-variance decomposition__

- The training MSE declines monotonically as flexibility increases, this is because as the flexibility increases the *f* curve fits the observed data more closely.
- The test MSE initially declines as flexibility increases but at some point it levels off and then starts to increase again (U-shape), this is because when *f* curve yields a small training MSE but the largest test MSE we are actually overfitting the data (our procedure tries too hard to find patterns in the training data that are caused by chance rather than by true properties of the unknown *f*)
- The squared bias decrease and the variance increases; Generally, as we use more flexible methods, the variance will increase and the bias will decrease
- The irreducible error is a constant, so it is parallel line. This curve lies below the test MSE curve because the expected test MSE will always be greater than Var(ε).